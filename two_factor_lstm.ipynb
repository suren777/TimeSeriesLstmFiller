{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as kf\n",
    "from CODE.utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_2f_model(n_units, input_shape, file=None):\n",
    "    window_size,input_dim = input_shape\n",
    "    input_1 = kf.layers.Input(shape=(window_size,input_dim-1))\n",
    "    input_2 = kf.layers.Input(shape=(window_size - 1, 1))\n",
    "\n",
    "    lstm_1= kf.layers.LSTM(n_units, return_state=True)\n",
    "    output,  output_h, output_c = lstm_1(input_1)\n",
    "    encoder_states = [output_h, output_c]\n",
    "\n",
    "    lstm_2 = kf.layers.LSTM(n_units)\n",
    "    lstm_out = lstm_2(input_2, initial_state=encoder_states)\n",
    "\n",
    "    dense_in = kf.layers.Dense(n_units//2,activation='tanh')(lstm_out)\n",
    "    dense_out = kf.layers.Dense(1, activation='linear', use_bias=False)(dense_in)\n",
    "\n",
    "    model = kf.models.Model(inputs=[input_1, input_2], outputs=[dense_out])\n",
    "    model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "    if file == file:\n",
    "        try:\n",
    "            model.load_weights(file)\n",
    "        except:\n",
    "            pass\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 5\n",
    "n_units = 200\n",
    "\n",
    "df = load_dfs()\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "diff_df = df.pct_change(1).iloc[1:,:]\n",
    "# scaler.fit(df.values)\n",
    "#X1, X2, Y = generate_windows_for_two_factor(df, window_size,scaler=scaler)\n",
    "X1, X2, Y = generate_windows_for_two_factor(diff_df, window_size)\n",
    "\n",
    "file = 'FILES/Models/lstm_2f_model.hdf5'\n",
    "input_shape = (window_size,df.values.shape[1])\n",
    "model = create_2f_model(n_units, input_shape, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 0\n",
    "for i in range(epochs):\n",
    "    hist = model.fit(x=[X1, X2],\n",
    "              y=Y,\n",
    "              batch_size=512,\n",
    "              verbose=2,\n",
    "              epochs=1,\n",
    "              validation_split=0.05,\n",
    "              callbacks=[])\n",
    "    if i > 0:\n",
    "        if hist.history['val_loss'][-1]<val_loss:\n",
    "            val_loss = hist.history['val_loss'][-1]\n",
    "            print(\"New val_loss: {}\\t epoch: {}\".format(val_loss,i))\n",
    "            model.save_weights(file)\n",
    "    else:\n",
    "        val_loss =  hist.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = 100\n",
    "test_df = df.iloc[0:300,0].to_frame()\n",
    "test_df['GAP'] = test_df.iloc[:,0]\n",
    "test_df['GAP'].iloc[start:start+100]=np.nan\n",
    "test_df = test_df.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_pred, Y_actual=list(), list()\n",
    "for id in range(start,start+100):\n",
    "    if id == start:\n",
    "        x2 = X2[id].reshape(-1, window_size - 1, 1)\n",
    "    x1 = X1[id].reshape(-1,window_size,input_shape[1]-1)\n",
    "    Y_pred.append(model.predict([x1, x2]).flatten())\n",
    "    Y_actual.append(Y[id].flatten())\n",
    "    x2[0, :-1, 0] = x2[0, 1:, 0]\n",
    "    x2[0,-1,0] = Y_pred[-1]\n",
    "\n",
    "test_df['Predicted']=np.nan\n",
    "test_df['Predicted'].iloc[start:start+100]=Y_pred\n",
    "test_df.plot()\n"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
